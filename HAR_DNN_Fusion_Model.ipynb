{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from keras.layers import Conv2D, MaxPooling2D, Conv1D, Flatten\n",
    "from keras.layers.convolutional import Conv3D\n",
    "from keras.layers.convolutional_recurrent import ConvLSTM2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "# Importing libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, TimeDistributed\n",
    "from keras.layers.core import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activities are the class labels\n",
    "# It is a 6 class classification\n",
    "ACTIVITIES = {\n",
    "    0: 'WALKING',\n",
    "    1: 'WALKING_UPSTAIRS',\n",
    "    2: 'WALKING_DOWNSTAIRS',\n",
    "    3: 'SITTING',\n",
    "    4: 'STANDING',\n",
    "    5: 'LAYING',\n",
    "}\n",
    "\n",
    "# Utility function to print the confusion matrix\n",
    "def confusion_matrix(Y_true, Y_pred):\n",
    "    Y_true = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_true, axis=1)])\n",
    "    Y_pred = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_pred, axis=1)])\n",
    "\n",
    "    return pd.crosstab(Y_true, Y_pred, rownames=['True'], colnames=['Pred'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data directory\n",
    "DATADIR = 'UCI_HAR_Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw data signals\n",
    "# Signals are from Accelerometer and Gyroscope\n",
    "# The signals are in x,y,z directions\n",
    "# Sensor signals are filtered to have only body acceleration\n",
    "# excluding the acceleration due to gravity\n",
    "# Triaxial acceleration from the accelerometer is total acceleration\n",
    "SIGNALS = [\n",
    "    \"body_acc_x\",\n",
    "    \"body_acc_y\",\n",
    "    \"body_acc_z\",\n",
    "    \"body_gyro_x\",\n",
    "    \"body_gyro_y\",\n",
    "    \"body_gyro_z\",\n",
    "    \"total_acc_x\",\n",
    "    \"total_acc_y\",\n",
    "    \"total_acc_z\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to read the data from csv file\n",
    "def _read_csv(filename):\n",
    "    return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
    "\n",
    "# Utility function to load the load\n",
    "def load_signals(subset):\n",
    "    signals_data = []\n",
    "\n",
    "    for signal in SIGNALS:\n",
    "        filename = f'UCI_HAR_Dataset/{subset}/Inertial Signals/{signal}_{subset}.txt'\n",
    "        signals_data.append(\n",
    "            _read_csv(filename).as_matrix()\n",
    "        ) \n",
    "\n",
    "    # Transpose is used to change the dimensionality of the output,\n",
    "    # aggregating the signals by combination of sample/timestep.\n",
    "    # Resultant shape is (7352 train/2947 test samples, 128 timesteps, 9 signals)\n",
    "    return np.transpose(signals_data, (1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_y(subset):\n",
    "    \"\"\"\n",
    "    The objective that we are trying to predict is a integer, from 1 to 6,\n",
    "    that represents a human activity. We return a binary representation of \n",
    "    every sample objective as a 6 bits vector using One Hot Encoding\n",
    "    (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n",
    "    \"\"\"\n",
    "    filename = f'UCI_HAR_Dataset/{subset}/y_{subset}.txt'\n",
    "    y = _read_csv(filename)[0]\n",
    "\n",
    "    return pd.get_dummies(y).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"\n",
    "    Obtain the dataset from multiple files.\n",
    "    Returns: X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    X_train, X_test = load_signals('train'), load_signals('test')\n",
    "    y_train, y_test = load_y('train'), load_y('test')\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing tensorflow\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuring a session\n",
    "session_conf = tf.ConfigProto(\n",
    "    intra_op_parallelism_threads=1,\n",
    "    inter_op_parallelism_threads=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Keras\n",
    "from keras import backend as K\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing parameters\n",
    "epochs = 30\n",
    "batch_size = 30\n",
    "# n_hidden = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to count the number of classes\n",
    "def _count_classes(y):\n",
    "    return len(set([tuple(category) for category in y]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The DNN-based Fusion Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://arxiv.org/pdf/1805.07020.pdf\n",
    "- https://www.researchgate.net/publication/305649713_Deep_learning_for_human_activity_recognition_A_resource_efficient_implementation_on_low-power_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://machinelearningmastery.com/how-to-develop-rnn-models-for-human-activity-recognition-time-series-classification/\n",
    "# https://machinelearningmastery.com/deep-learning-models-for-human-activity-recognition/\n",
    "# https://github.com/UdiBhaskar/Human-Activity-Recognition--Using-Deep-NN/blob/master/Human%20Activity%20Detection-Without%20Verbose%20.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test data for model-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the train and test data\n",
    "X_train, X_test, Y_train, Y_test = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test data for model-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting axis specific data\n",
    "X_train_1 = X_train[:,:,[1,2,3,4,5,6]]\n",
    "X_test_1 = X_test[:,:,[1,2,3,4,5,6]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test data for model-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting axis specific data\n",
    "X_train_2 = X_train[:,:,[1,2,3,4]]\n",
    "X_test_2 = X_test[:,:,[1,2,3,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_2 = X_train[:,:,[5,6,7,8]]\n",
    "# X_test_2 = X_test[:,:,[5,6,7,8]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # selecting axis specific data\n",
    "# X_train_1 = X_train[:,:,[3,4,5,6,7,8]]\n",
    "# X_train_2 = X_train[:,:,[3,4,6,7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # selecting axis specific data\n",
    "# X_test_1 = X_test[:,:,[3,4,5,6,7,8]]\n",
    "# X_test_2 = X_test[:,:,[3,4,6,7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "9\n",
      "7352\n"
     ]
    }
   ],
   "source": [
    "timesteps = len(X_train[0])\n",
    "input_dim = len(X_train[0][0])\n",
    "n_classes = _count_classes(Y_train)\n",
    "print(timesteps)\n",
    "print(input_dim)\n",
    "print(len(X_train))\n",
    "num_classes = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding and Improving Deep Neural Network for Activity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import make_classification\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 128, 9, 1)\n"
     ]
    }
   ],
   "source": [
    "# Test and Train data reshaping for 1st dataset\n",
    "# input image dimensions\n",
    "\n",
    "img_rows, img_cols = 128, 9\n",
    "# an activity is governed by sequence of activities. 8 sequences informations are given to CNN model which will be later given to LSTM unit as a sequence information.\n",
    "# 7352 = 919*8\n",
    "X_train = X_train.reshape(919,8,128,9,1)\n",
    "Y_train = Y_train.reshape(919,8,6)\n",
    "\n",
    "# removing last 3 data pointjust to make test data sequence compatible\n",
    "# 2944 = 368*8\n",
    "X_test = X_test[:-3]\n",
    "Y_test = Y_test[:-3]\n",
    "\n",
    "X_test = X_test.reshape(368,8,128,9,1)\n",
    "Y_test = Y_test.reshape(368,8,6)\n",
    "\n",
    "# Input shape for model-1\n",
    "input_shape_1 = ( X_train.shape[1], X_train.shape[2], X_train.shape[3], X_train.shape[4])\n",
    "print(input_shape_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((919, 8, 128, 9, 1), (368, 8, 128, 9, 1))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 128, 6, 1)\n"
     ]
    }
   ],
   "source": [
    "# Test and Train data reshaping for 1st dataset\n",
    "# input image dimensions\n",
    "\n",
    "img_rows, img_cols = 128, 6\n",
    "# an activity is governed by sequence of activities. 8 sequences informations are given to CNN model which will be later given to LSTM unit as a sequence information.\n",
    "# 7352 = 919*8\n",
    "X_train_1 = X_train_1.reshape(919,8,128,6,1)\n",
    "\n",
    "# removing last 3 data pointjust to make test data sequence compatible\n",
    "# 2944 = 368*8\n",
    "X_test_1 = X_test_1[:-3]\n",
    "X_test_1 = X_test_1.reshape(368,8,128,6,1)\n",
    "\n",
    "# Input shape for model-2\n",
    "input_shape_2 = (X_train_1.shape[1], X_train_1.shape[2], X_train_1.shape[3], X_train_1.shape[4])\n",
    "print(input_shape_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((919, 8, 128, 6, 1), (368, 8, 128, 6, 1))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_1.shape, X_test_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 128, 4, 1)\n"
     ]
    }
   ],
   "source": [
    "# Test and Train data reshaping for 1st dataset\n",
    "# input image dimensions\n",
    "\n",
    "img_rows, img_cols = 128, 4\n",
    "# an activity is governed by sequence of activities. 8 sequences are given to CNN model which will be later given to LSTM unit as a sequence information.\n",
    "# 7352 = 919*8\n",
    "X_train_2 = X_train_2.reshape(919,8,128,4,1)\n",
    "\n",
    "# removing last 3 data pointjust to make test data sequence compatible\n",
    "# 2944 = 368*8\n",
    "X_test_2 = X_test_2[:-3]\n",
    "X_test_2 = X_test_2.reshape(368,8,128,4,1)\n",
    "\n",
    "# Input shape for model-2\n",
    "input_shape_3 = (X_train_2.shape[1], X_train_2.shape[2], X_train_2.shape[3], X_train_2.shape[4])\n",
    "print(input_shape_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((919, 8, 128, 4, 1), (368, 8, 128, 4, 1))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_2.shape, X_test_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(shape_cnn, shape_lstm):\n",
    "    # print(shape_cnn, shape_lstm)\n",
    "    model = Sequential()\n",
    "    model.add(TimeDistributed(Conv2D(128, kernel_size=(5,1),  activation='relu', input_shape= shape_cnn)))\n",
    "    model.add(TimeDistributed(Conv2D(64, (5, 1), activation='relu')))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(TimeDistributed(Conv2D(32, (5, 1), activation='relu')))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    # model.add(TimeDistributed(Dense(32, activation='relu')))\n",
    "    model.add(LSTM(units=64, return_sequences=True, input_shape = shape_lstm))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    # compiling the model\n",
    "    # model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model-1 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/manish/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/manish/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/30\n",
      "919/919 [==============================] - 83s 91ms/step - loss: 0.7057 - accuracy: 0.6942\n",
      "Epoch 2/30\n",
      "919/919 [==============================] - 84s 91ms/step - loss: 0.4070 - accuracy: 0.8470\n",
      "Epoch 3/30\n",
      "919/919 [==============================] - 82s 89ms/step - loss: 0.2889 - accuracy: 0.9007\n",
      "Epoch 4/30\n",
      "919/919 [==============================] - 82s 89ms/step - loss: 0.2282 - accuracy: 0.9233\n",
      "Epoch 5/30\n",
      "919/919 [==============================] - 82s 89ms/step - loss: 0.1990 - accuracy: 0.9329\n",
      "Epoch 6/30\n",
      "919/919 [==============================] - 82s 90ms/step - loss: 0.2003 - accuracy: 0.9329\n",
      "Epoch 7/30\n",
      "919/919 [==============================] - 83s 91ms/step - loss: 0.1572 - accuracy: 0.9524\n",
      "Epoch 8/30\n",
      "919/919 [==============================] - 83s 90ms/step - loss: 0.1294 - accuracy: 0.9580\n",
      "Epoch 9/30\n",
      "919/919 [==============================] - 90s 98ms/step - loss: 0.1172 - accuracy: 0.9638\n",
      "Epoch 10/30\n",
      "919/919 [==============================] - 84s 91ms/step - loss: 0.1049 - accuracy: 0.9638\n",
      "Epoch 11/30\n",
      "919/919 [==============================] - 94s 103ms/step - loss: 0.1074 - accuracy: 0.9622\n",
      "Epoch 12/30\n",
      "919/919 [==============================] - 98s 106ms/step - loss: 0.0919 - accuracy: 0.9663\n",
      "Epoch 13/30\n",
      "919/919 [==============================] - 108s 117ms/step - loss: 0.0896 - accuracy: 0.9680\n",
      "Epoch 14/30\n",
      "919/919 [==============================] - 99s 108ms/step - loss: 0.0875 - accuracy: 0.9672\n",
      "Epoch 15/30\n",
      "919/919 [==============================] - 96s 104ms/step - loss: 0.0848 - accuracy: 0.9675\n",
      "Epoch 16/30\n",
      "919/919 [==============================] - 144s 156ms/step - loss: 0.0854 - accuracy: 0.9693\n",
      "Epoch 17/30\n",
      "919/919 [==============================] - 113s 123ms/step - loss: 0.0865 - accuracy: 0.9694\n",
      "Epoch 18/30\n",
      "919/919 [==============================] - 102s 111ms/step - loss: 0.0823 - accuracy: 0.9725\n",
      "Epoch 19/30\n",
      "919/919 [==============================] - 93s 101ms/step - loss: 0.0762 - accuracy: 0.9679\n",
      "Epoch 20/30\n",
      "919/919 [==============================] - 85s 92ms/step - loss: 0.0763 - accuracy: 0.9706\n",
      "Epoch 21/30\n",
      "919/919 [==============================] - 115s 125ms/step - loss: 0.0769 - accuracy: 0.9735\n",
      "Epoch 22/30\n",
      "919/919 [==============================] - 94s 102ms/step - loss: 0.0782 - accuracy: 0.9728\n",
      "Epoch 23/30\n",
      "919/919 [==============================] - 87s 95ms/step - loss: 0.0700 - accuracy: 0.9744\n",
      "Epoch 24/30\n",
      "919/919 [==============================] - 92s 100ms/step - loss: 0.0697 - accuracy: 0.9751\n",
      "Epoch 25/30\n",
      "919/919 [==============================] - 91s 99ms/step - loss: 0.0740 - accuracy: 0.9735\n",
      "Epoch 26/30\n",
      "919/919 [==============================] - 102s 111ms/step - loss: 0.0794 - accuracy: 0.9698\n",
      "Epoch 27/30\n",
      "919/919 [==============================] - 103s 112ms/step - loss: 0.0744 - accuracy: 0.9761\n",
      "Epoch 28/30\n",
      "919/919 [==============================] - 104s 113ms/step - loss: 0.0865 - accuracy: 0.9716\n",
      "Epoch 29/30\n",
      "919/919 [==============================] - 120s 131ms/step - loss: 0.0904 - accuracy: 0.9724\n",
      "Epoch 30/30\n",
      "919/919 [==============================] - 92s 100ms/step - loss: 0.0767 - accuracy: 0.9727\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f6d64267828>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1 = get_model(input_shape_1,(input_shape_1[1],input_shape_1[2]))\n",
    "model_1.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.save('CNN_LSTM_Model_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 7s 20ms/step\n"
     ]
    }
   ],
   "source": [
    "score = model_1.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.22175494484279468, 0.9225543737411499]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model-2 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "919/919 [==============================] - 60s 65ms/step - loss: 1.1910 - accuracy: 0.4777\n",
      "Epoch 2/30\n",
      "919/919 [==============================] - 58s 63ms/step - loss: 0.6051 - accuracy: 0.7135\n",
      "Epoch 3/30\n",
      "919/919 [==============================] - 56s 61ms/step - loss: 0.4745 - accuracy: 0.7671\n",
      "Epoch 4/30\n",
      "919/919 [==============================] - 54s 59ms/step - loss: 0.4129 - accuracy: 0.7916\n",
      "Epoch 5/30\n",
      "919/919 [==============================] - 62s 68ms/step - loss: 0.3534 - accuracy: 0.8301\n",
      "Epoch 6/30\n",
      "919/919 [==============================] - 60s 65ms/step - loss: 0.3053 - accuracy: 0.8546\n",
      "Epoch 7/30\n",
      "919/919 [==============================] - 54s 59ms/step - loss: 0.3044 - accuracy: 0.8523\n",
      "Epoch 8/30\n",
      "919/919 [==============================] - 54s 58ms/step - loss: 0.2536 - accuracy: 0.8761\n",
      "Epoch 9/30\n",
      "919/919 [==============================] - 53s 58ms/step - loss: 0.2234 - accuracy: 0.9059\n",
      "Epoch 10/30\n",
      "919/919 [==============================] - 53s 58ms/step - loss: 0.2066 - accuracy: 0.9056\n",
      "Epoch 11/30\n",
      "919/919 [==============================] - 52s 57ms/step - loss: 0.1909 - accuracy: 0.9120\n",
      "Epoch 12/30\n",
      "919/919 [==============================] - 53s 57ms/step - loss: 0.1736 - accuracy: 0.9270\n",
      "Epoch 13/30\n",
      "919/919 [==============================] - 55s 60ms/step - loss: 0.1551 - accuracy: 0.9332\n",
      "Epoch 14/30\n",
      "919/919 [==============================] - 64s 70ms/step - loss: 0.1436 - accuracy: 0.9361\n",
      "Epoch 15/30\n",
      "919/919 [==============================] - 59s 64ms/step - loss: 0.1382 - accuracy: 0.9467\n",
      "Epoch 16/30\n",
      "919/919 [==============================] - 56s 61ms/step - loss: 0.1336 - accuracy: 0.9431\n",
      "Epoch 17/30\n",
      "919/919 [==============================] - 56s 61ms/step - loss: 0.1260 - accuracy: 0.9465\n",
      "Epoch 18/30\n",
      "919/919 [==============================] - 54s 59ms/step - loss: 0.1091 - accuracy: 0.9584\n",
      "Epoch 19/30\n",
      "919/919 [==============================] - 58s 63ms/step - loss: 0.0785 - accuracy: 0.9755\n",
      "Epoch 20/30\n",
      "919/919 [==============================] - 59s 64ms/step - loss: 0.0711 - accuracy: 0.9767\n",
      "Epoch 21/30\n",
      "919/919 [==============================] - 73s 79ms/step - loss: 0.0727 - accuracy: 0.9752\n",
      "Epoch 22/30\n",
      "919/919 [==============================] - 65s 71ms/step - loss: 0.0676 - accuracy: 0.9797\n",
      "Epoch 23/30\n",
      "919/919 [==============================] - 81s 88ms/step - loss: 0.0555 - accuracy: 0.9816\n",
      "Epoch 24/30\n",
      "919/919 [==============================] - 76s 83ms/step - loss: 0.0515 - accuracy: 0.9860\n",
      "Epoch 25/30\n",
      "919/919 [==============================] - 107s 117ms/step - loss: 0.0505 - accuracy: 0.9842\n",
      "Epoch 26/30\n",
      "919/919 [==============================] - 102s 111ms/step - loss: 0.0375 - accuracy: 0.9894\n",
      "Epoch 27/30\n",
      "919/919 [==============================] - 72s 78ms/step - loss: 0.0363 - accuracy: 0.9888\n",
      "Epoch 28/30\n",
      "919/919 [==============================] - 74s 80ms/step - loss: 0.0355 - accuracy: 0.9899\n",
      "Epoch 29/30\n",
      "919/919 [==============================] - 55s 60ms/step - loss: 0.0247 - accuracy: 0.9933\n",
      "Epoch 30/30\n",
      "919/919 [==============================] - 60s 65ms/step - loss: 0.0607 - accuracy: 0.9804\n"
     ]
    }
   ],
   "source": [
    "model_2 = get_model(input_shape_2,(input_shape_2[1],input_shape_2[2]))\n",
    "model_2.fit(X_train_1, Y_train, batch_size=batch_size, epochs=epochs, verbose=1)\n",
    "model_2.save('CNN_LSTM_Model_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 5s 14ms/step\n"
     ]
    }
   ],
   "source": [
    "score = model_2.evaluate(X_test_1, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1947319541612397, 0.9290081262588501]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model-3 Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "919/919 [==============================] - 74s 81ms/step - loss: 0.9507 - accuracy: 0.6129\n",
      "Epoch 2/30\n",
      "919/919 [==============================] - 73s 79ms/step - loss: 0.6082 - accuracy: 0.7337\n",
      "Epoch 3/30\n",
      "919/919 [==============================] - 50s 55ms/step - loss: 0.5404 - accuracy: 0.7558\n",
      "Epoch 4/30\n",
      "919/919 [==============================] - 37s 40ms/step - loss: 0.4534 - accuracy: 0.8013\n",
      "Epoch 5/30\n",
      "919/919 [==============================] - 37s 40ms/step - loss: 0.4212 - accuracy: 0.8184\n",
      "Epoch 6/30\n",
      "919/919 [==============================] - 36s 39ms/step - loss: 0.3842 - accuracy: 0.8387\n",
      "Epoch 7/30\n",
      "919/919 [==============================] - 37s 40ms/step - loss: 0.3982 - accuracy: 0.8335\n",
      "Epoch 8/30\n",
      "919/919 [==============================] - 36s 39ms/step - loss: 0.3565 - accuracy: 0.8589\n",
      "Epoch 9/30\n",
      "919/919 [==============================] - 39s 43ms/step - loss: 0.3052 - accuracy: 0.8974\n",
      "Epoch 10/30\n",
      "919/919 [==============================] - 49s 54ms/step - loss: 0.3033 - accuracy: 0.8823\n",
      "Epoch 11/30\n",
      "919/919 [==============================] - 50s 55ms/step - loss: 0.2569 - accuracy: 0.9060\n",
      "Epoch 12/30\n",
      "919/919 [==============================] - 38s 41ms/step - loss: 0.2215 - accuracy: 0.9210\n",
      "Epoch 13/30\n",
      "919/919 [==============================] - 37s 40ms/step - loss: 0.2273 - accuracy: 0.9181\n",
      "Epoch 14/30\n",
      "919/919 [==============================] - 42s 46ms/step - loss: 0.1847 - accuracy: 0.9346\n",
      "Epoch 15/30\n",
      "919/919 [==============================] - 42s 46ms/step - loss: 0.1677 - accuracy: 0.9406\n",
      "Epoch 16/30\n",
      "919/919 [==============================] - 40s 43ms/step - loss: 0.1385 - accuracy: 0.9536\n",
      "Epoch 17/30\n",
      "919/919 [==============================] - 40s 44ms/step - loss: 0.1322 - accuracy: 0.9544\n",
      "Epoch 18/30\n",
      "919/919 [==============================] - 37s 40ms/step - loss: 0.1295 - accuracy: 0.9548\n",
      "Epoch 19/30\n",
      "919/919 [==============================] - 51s 56ms/step - loss: 0.1144 - accuracy: 0.9559\n",
      "Epoch 20/30\n",
      "919/919 [==============================] - 54s 58ms/step - loss: 0.1102 - accuracy: 0.9600\n",
      "Epoch 21/30\n",
      "919/919 [==============================] - 41s 44ms/step - loss: 0.1049 - accuracy: 0.9634\n",
      "Epoch 22/30\n",
      "919/919 [==============================] - 42s 45ms/step - loss: 0.1019 - accuracy: 0.9622\n",
      "Epoch 23/30\n",
      "919/919 [==============================] - 42s 46ms/step - loss: 0.1025 - accuracy: 0.9619\n",
      "Epoch 24/30\n",
      "919/919 [==============================] - 41s 44ms/step - loss: 0.0898 - accuracy: 0.9640\n",
      "Epoch 25/30\n",
      "919/919 [==============================] - 43s 46ms/step - loss: 0.0916 - accuracy: 0.9634\n",
      "Epoch 26/30\n",
      "919/919 [==============================] - 46s 50ms/step - loss: 0.0905 - accuracy: 0.9627\n",
      "Epoch 27/30\n",
      "919/919 [==============================] - 69s 75ms/step - loss: 0.0872 - accuracy: 0.9663\n",
      "Epoch 28/30\n",
      "919/919 [==============================] - 49s 53ms/step - loss: 0.0813 - accuracy: 0.9698\n",
      "Epoch 29/30\n",
      "919/919 [==============================] - 83s 90ms/step - loss: 0.0816 - accuracy: 0.9663\n",
      "Epoch 30/30\n",
      "919/919 [==============================] - 52s 56ms/step - loss: 0.0818 - accuracy: 0.9689\n"
     ]
    }
   ],
   "source": [
    "model_3 = get_model(input_shape_3,(input_shape_3[1],input_shape_3[2]))\n",
    "model_3.fit(X_train_2, Y_train, batch_size=batch_size, epochs=epochs, verbose=1)\n",
    "model_3.save('CNN_LSTM_Model_3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 3s 9ms/step\n"
     ]
    }
   ],
   "source": [
    "score = model_3.evaluate(X_test_2, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.23070418964261594, 0.9161005616188049]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting mechanism for the final classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = Y_test.reshape(2944,6)\n",
    "\n",
    "y1 = model_1.predict_proba(X_test)\n",
    "y1 = y1.reshape(2944,6)\n",
    "\n",
    "y2 = model_2.predict_proba(X_test_1)\n",
    "y2 = y2.reshape(2944,6)\n",
    "\n",
    "y3 = model_3.predict_proba(X_test_2)\n",
    "y3 = y3.reshape(2944,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for i in range(len(y1)):\n",
    "    tmp = [0,0,0,0,0,0]\n",
    "    \n",
    "    op1 = np.amax(y1[i])\n",
    "    index1 = y1[i].argmax(axis=0)\n",
    "    tmp[index1] = 1\n",
    "    \n",
    "    op2 = np.amax(y2[i])\n",
    "    index2 = y2[i].argmax(axis=0)\n",
    "    tmp[index2] = 1\n",
    "    \n",
    "    op3 = np.amax(y3[i])\n",
    "    index3 = y3[i].argmax(axis=0)\n",
    "    tmp[index3] = 1\n",
    "    \n",
    "    l = [op1, op2, op3]\n",
    "    if sum(tmp)==1:\n",
    "        y_pred.append(tmp)\n",
    "    \n",
    "    else:\n",
    "        tmp = [0,0,0,0,0,0]\n",
    "        ind = l.index(max(l))\n",
    "        if ind == 0:\n",
    "            tmp[index1] = 1\n",
    "            y_pred.append(tmp)\n",
    "        \n",
    "        elif ind ==1:\n",
    "            tmp[index2] = 1\n",
    "            y_pred.append(tmp)\n",
    "        \n",
    "        elif ind ==2:\n",
    "            tmp[index3] = 1\n",
    "            y_pred.append(tmp)\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 537        0         0        0                   0   \n",
      "SITTING                  0      446        43        0                   0   \n",
      "STANDING                 0       19       507        1                   0   \n",
      "WALKING                  1        0         0      479                  15   \n",
      "WALKING_DOWNSTAIRS       0        0         0       21                 389   \n",
      "WALKING_UPSTAIRS         0        0         0        3                  15   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                             0  \n",
      "SITTING                            2  \n",
      "STANDING                           5  \n",
      "WALKING                            1  \n",
      "WALKING_DOWNSTAIRS                10  \n",
      "WALKING_UPSTAIRS                 450  \n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "y_pred = np.array(y_pred)\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9538043478260869"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function returning a compiled network\n",
    "def create_network(n_hidden, drop):\n",
    "    \n",
    "    # Initiliazing the sequential model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Configuring the parameters\n",
    "    model.add(LSTM(units=n_hidden, dropout=drop, return_sequences=True, input_shape=(timesteps, input_dim)))\n",
    "    model.add(LSTM(units=n_hidden, dropout=drop, return_sequences=False))\n",
    "\n",
    "    # Adding a dropout layer\n",
    "    model.add(Dropout(drop))\n",
    "    # Adding a dense output layer with sigmoid activation\n",
    "    model.add(Dense(n_classes, activation='sigmoid'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "    # model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap Keras model so it can be used by scikit-learn\n",
    "neural_network = KerasClassifier(build_fn=create_network, verbose=0, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create grid search\n",
    "grid = GridSearchCV(estimator=neural_network, param_grid=hyperparameters, verbose=10, cv=2)\n",
    "\n",
    "# Fit grid search\n",
    "grid_result = grid.fit(X_train, Y_train)\n",
    "grid_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing parameters\n",
    "epochs = 20\n",
    "batch_size = 50\n",
    "# n_hidden = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_8 (LSTM)                (None, 128, 264)          289344    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 128, 264)          0         \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 264)               558624    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 264)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 6)                 1590      \n",
      "=================================================================\n",
      "Total params: 849,558\n",
      "Trainable params: 849,558\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n_hidden = 264\n",
    "drop= 0.7\n",
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(units = n_hidden, return_sequences=True, input_shape=(timesteps, input_dim)))\n",
    "model.add(Dropout(drop))\n",
    "model.add(LSTM(units =  n_hidden, return_sequences=False))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(drop))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7352/7352 [==============================] - 227s 31ms/step - loss: 1.3779 - accuracy: 0.4022\n",
      "Epoch 2/20\n",
      "7352/7352 [==============================] - 229s 31ms/step - loss: 1.2833 - accuracy: 0.4256\n",
      "Epoch 3/20\n",
      "7352/7352 [==============================] - 227s 31ms/step - loss: 1.0420 - accuracy: 0.5279\n",
      "Epoch 4/20\n",
      "7352/7352 [==============================] - 225s 31ms/step - loss: 0.8007 - accuracy: 0.6323\n",
      "Epoch 5/20\n",
      "7352/7352 [==============================] - 222s 30ms/step - loss: 0.6743 - accuracy: 0.6783\n",
      "Epoch 6/20\n",
      "7352/7352 [==============================] - 225s 31ms/step - loss: 0.5519 - accuracy: 0.7628\n",
      "Epoch 7/20\n",
      "7352/7352 [==============================] - 228s 31ms/step - loss: 0.4023 - accuracy: 0.8564\n",
      "Epoch 8/20\n",
      "7352/7352 [==============================] - 223s 30ms/step - loss: 0.2483 - accuracy: 0.9125\n",
      "Epoch 9/20\n",
      "7352/7352 [==============================] - 225s 31ms/step - loss: 0.2317 - accuracy: 0.9279\n",
      "Epoch 10/20\n",
      "7352/7352 [==============================] - 229s 31ms/step - loss: 0.1892 - accuracy: 0.9323\n",
      "Epoch 11/20\n",
      "7352/7352 [==============================] - 227s 31ms/step - loss: 0.1811 - accuracy: 0.9320\n",
      "Epoch 12/20\n",
      "7352/7352 [==============================] - 226s 31ms/step - loss: 0.1698 - accuracy: 0.9416\n",
      "Epoch 13/20\n",
      "7352/7352 [==============================] - 231s 31ms/step - loss: 0.1661 - accuracy: 0.9426\n",
      "Epoch 14/20\n",
      "7352/7352 [==============================] - 233s 32ms/step - loss: 0.1742 - accuracy: 0.9418\n",
      "Epoch 15/20\n",
      "7352/7352 [==============================] - 231s 31ms/step - loss: 0.1599 - accuracy: 0.9321\n",
      "Epoch 16/20\n",
      "7352/7352 [==============================] - 227s 31ms/step - loss: 0.1661 - accuracy: 0.9464\n",
      "Epoch 17/20\n",
      "7352/7352 [==============================] - 228s 31ms/step - loss: 0.1453 - accuracy: 0.9464\n",
      "Epoch 18/20\n",
      "7352/7352 [==============================] - 224s 30ms/step - loss: 0.2291 - accuracy: 0.9295\n",
      "Epoch 19/20\n",
      "7352/7352 [==============================] - 227s 31ms/step - loss: 0.1312 - accuracy: 0.9509\n",
      "Epoch 20/20\n",
      "7352/7352 [==============================] - 228s 31ms/step - loss: 0.1580 - accuracy: 0.9474\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fda53a0a7b8>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 534        0         0        0                   0   \n",
      "SITTING                  5      381       103        0                   0   \n",
      "STANDING                 0       96       436        0                   0   \n",
      "WALKING                  0        0         0      472                  24   \n",
      "WALKING_DOWNSTAIRS       0        0         0        6                 401   \n",
      "WALKING_UPSTAIRS         0        2         0       24                   5   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                             3  \n",
      "SITTING                            2  \n",
      "STANDING                           0  \n",
      "WALKING                            0  \n",
      "WALKING_DOWNSTAIRS                13  \n",
      "WALKING_UPSTAIRS                 440  \n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model1.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 6s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "score = model1.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4655049461999594, 0.9039701223373413]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------------+\n",
      "| Architecture | Test Accuracy |\n",
      "+--------------+---------------+\n",
      "|  DNN Fusion  |      0.95     |\n",
      "|     LSTM     |      0.90     |\n",
      "+--------------+---------------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable    \n",
    "x = PrettyTable()\n",
    "x.field_names = [\"Architecture\", \"Test Accuracy\"]\n",
    "x.add_row([\"DNN Fusion\", \"0.95\"])\n",
    "x.add_row([\"LSTM\", \"0.90\"])\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With a simple 2 layer architecture we got 90.39% accuracy and a loss of 0.46.\n",
    "- Accuracy is way better for DNN fusion based model.\n",
    "- by looking at confusion matrix we can see that DNN fusion model has very less confusion between sitting and standing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
